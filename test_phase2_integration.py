"""
Phase 2 Integration Test - Document Classification and Enhanced Processing
Demonstrates the complete automated workflow
"""

import os
import tempfile
from datetime import datetime

# Add app directory to path
import sys
sys.path.insert(0, os.path.dirname(__file__))

from modules.doc_converter import DocumentClassifier
from doc_converter.processing import EnhancedProcessor


def demonstrate_phase2_workflow():
    """Demonstrate the complete Phase 2 workflow"""
    print("üöÄ Phase 2 Integration Demo - Automated Document Processing\n")
    
    # Create test document
    with tempfile.TemporaryDirectory() as temp_dir:
        # Create a comprehensive test document
        test_file = os.path.join(temp_dir, "nscale-complete-guide.md")
        with open(test_file, 'w', encoding='utf-8') as f:
            f.write("""# nscale Benutzerhandbuch v3.0

Version: 3.0.1
Datum: Januar 2024
Autor: nscale Team
Keywords: DMS, Dokumentenmanagement, Enterprise, Digitale Akte

## Inhaltsverzeichnis

1. [Einf√ºhrung](#einf√ºhrung)
2. [Installation](#installation)
3. [Konfiguration](#konfiguration)
4. [API-Referenz](#api-referenz)
5. [FAQ](#faq)

## Einf√ºhrung

nscale ist ein leistungsstarkes Dokumentenmanagementsystem (DMS) f√ºr Unternehmen.

### Hauptfunktionen

- **Digitale Aktenverwaltung** - Vollst√§ndige Digitalisierung Ihrer Dokumente
- **Versionskontrolle** - Automatische Versionierung aller √Ñnderungen
- **Workflow-Automatisierung** - Gesch√§ftsprozesse digital abbilden
- **Berechtigungsverwaltung** - Granulare Zugriffsrechte

## Installation

### Systemanforderungen

| Komponente | Mindestanforderung | Empfohlen |
|------------|--------------------|-----------|
| CPU        | 4 Cores            | 8 Cores   |
| RAM        | 8 GB               | 16 GB     |
| Festplatte | 100 GB             | 500 GB    |
| OS         | Windows 10         | Windows 11|

### Installationsschritte

1. Download der Installationsdatei von https://nscale.com/download
2. Ausf√ºhren des Installers als Administrator
3. Folgen Sie dem Setup-Assistenten

```bash
# Linux Installation
sudo apt-get update
sudo apt-get install nscale-server
sudo systemctl start nscale
```

## Konfiguration

### Datenbank-Konfiguration

Die Datenbankverbindung wird in der `config.yml` konfiguriert:

```yaml
database:
  type: postgresql
  host: localhost
  port: 5432
  name: nscale_db
  user: nscale_user
  password: ${DB_PASSWORD}
```

### Server-Einstellungen

| Einstellung | Standardwert | Beschreibung |
|-------------|--------------|--------------|
| port        | 8080         | HTTP-Port    |
| ssl_port    | 8443         | HTTPS-Port   |
| max_upload  | 100MB        | Max. Dateigr√∂√üe |

## API-Referenz

### Authentifizierung

```python
import requests

# Login
response = requests.post('https://api.nscale.com/auth/login', json={
    'username': 'user@example.com',
    'password': 'password'
})

token = response.json()['token']
headers = {'Authorization': f'Bearer {token}'}
```

### Dokumente abrufen

```python
# Alle Dokumente abrufen
documents = requests.get(
    'https://api.nscale.com/api/documents',
    headers=headers
).json()

# Einzelnes Dokument
doc = requests.get(
    'https://api.nscale.com/api/documents/123',
    headers=headers
).json()
```

## FAQ

**Q: Wie erstelle ich eine neue Akte?**
A: Klicken Sie auf "Neue Akte" in der Hauptnavigation und f√ºllen Sie die Metadatenfelder aus.

**Q: Kann ich Dokumente per E-Mail importieren?**
A: Ja, senden Sie Dokumente an import@ihr-nscale-server.de

**Q: Wie funktioniert die Volltextsuche?**
A: Die Suche indiziert automatisch alle Dokumente inklusive OCR f√ºr gescannte Dateien.

## Referenzen

- Offizielle Dokumentation: https://docs.nscale.com
- Support Portal: https://support.nscale.com
- Community Forum: https://community.nscale.com

Weitere Informationen finden Sie in unserem [Administratorhandbuch](#admin-guide).

---

¬© 2024 nscale GmbH. Alle Rechte vorbehalten.
""")
        
        print("üìÑ Test-Dokument erstellt: nscale-complete-guide.md")
        print("="*60)
        
        # Phase 1: Document Classification
        print("\nüìä PHASE 1: Dokumentklassifizierung")
        print("-"*40)
        
        classifier = DocumentClassifier()
        classification = classifier.classify_document(test_file)
        
        print(f"‚úÖ Dokumenttyp: {classification.metadata.document_type.value}")
        print(f"‚úÖ Kategorie: {classification.metadata.content_category.value}")
        print(f"‚úÖ Struktur: {classification.metadata.structure_type.value}")
        print(f"‚úÖ Sprache: {classification.metadata.language}")
        print(f"‚úÖ Verarbeitungsstrategie: {classification.processing_strategy.value}")
        print(f"‚úÖ Priorit√§t: {classification.priority_score:.2f}")
        print(f"‚úÖ Gesch√§tzte Zeit: {classification.estimated_processing_time:.1f}s")
        
        if classification.warnings:
            print("\n‚ö†Ô∏è  Warnungen:")
            for warning in classification.warnings:
                print(f"   - {warning}")
        
        if classification.recommendations:
            print("\nüí° Empfehlungen:")
            for rec in classification.recommendations:
                print(f"   - {rec}")
        
        # Phase 2: Enhanced Processing
        print("\n\nüîß PHASE 2: Erweiterte Dokumentenverarbeitung")
        print("-"*40)
        
        processor = EnhancedProcessor()
        result = processor.process_document(test_file, classification)
        
        print(f"‚úÖ Dokument-ID: {result.document_id}")
        print(f"‚úÖ Verarbeitungszeit: {result.processing_time:.3f}s")
        
        # Extracted Content
        print("\nüìä Extrahierte Inhalte:")
        print(f"   - Tabellen: {len(result.tables)}")
        print(f"   - Code-Snippets: {len(result.code_snippets)}")
        print(f"   - Referenzen: {len(result.references)}")
        print(f"   - Schl√ºsselpunkte: {len(result.structured_content['key_points'])}")
        
        # Metadata
        print("\nüìã Extrahierte Metadaten:")
        print(f"   - Titel: {result.metadata.title}")
        print(f"   - Version: {result.metadata.version}")
        print(f"   - Autoren: {', '.join(result.metadata.authors)}")
        print(f"   - Keywords: {', '.join(result.metadata.keywords)}")
        
        # Tables
        if result.tables:
            print("\nüìä Extrahierte Tabellen:")
            for i, table in enumerate(result.tables, 1):
                print(f"\n   Tabelle {i}: {table.caption or 'Ohne Titel'}")
                print(f"   - Headers: {', '.join(table.headers)}")
                print(f"   - Zeilen: {len(table.rows)}")
                if table.rows:
                    print(f"   - Beispiel: {table.rows[0]}")
        
        # Code Snippets
        if result.code_snippets:
            print("\nüíª Extrahierte Code-Snippets:")
            for i, snippet in enumerate(result.code_snippets, 1):
                print(f"\n   Snippet {i}:")
                print(f"   - Sprache: {snippet.language}")
                print(f"   - Zeilen: {len(snippet.code.split(chr(10)))}")
                print(f"   - Vorschau: {snippet.code[:50]}...")
        
        # References
        if result.references:
            print("\nüîó Extrahierte Referenzen:")
            internal = [r for r in result.references if r.ref_type == 'internal']
            external = [r for r in result.references if r.ref_type == 'external']
            print(f"   - Interne Links: {len(internal)}")
            print(f"   - Externe Links: {len(external)}")
            if external:
                print("   - Beispiele:")
                for ref in external[:3]:
                    print(f"     ‚Ä¢ {ref.target}")
        
        # Statistics
        print("\nüìà Dokumentstatistiken:")
        stats = result.statistics
        print(f"   - W√∂rter: {stats['text']['words']}")
        print(f"   - S√§tze: {stats['text']['sentences']}")
        print(f"   - Abs√§tze: {stats['text']['paragraphs']}")
        print(f"   - √úberschriften: {stats['structure']['headings']}")
        print(f"   - Listen: {stats['structure']['lists']}")
        
        # Structured Content
        print("\nüèóÔ∏è  Strukturierte Inhalte:")
        if 'sections' in result.structured_content:
            print(f"   - Sektionen: {len(result.structured_content['sections'])}")
        if 'qa_pairs' in result.structured_content:
            print(f"   - Q&A Paare: {len(result.structured_content['qa_pairs'])}")
        if 'definitions' in result.structured_content:
            print(f"   - Definitionen: {len(result.structured_content['definitions'])}")
        
        # Processing Warnings
        if result.warnings:
            print("\n‚ö†Ô∏è  Verarbeitungswarnungen:")
            for warning in result.warnings:
                print(f"   - {warning}")
        
        print("\n" + "="*60)
        print("‚ú® Phase 2 Integration erfolgreich abgeschlossen!")
        print("\nüéØ Zusammenfassung:")
        print("   ‚úÖ Automatische Dokumentklassifizierung")
        print("   ‚úÖ Intelligente Inhaltserkennung")
        print("   ‚úÖ Tabellen mit Kontext extrahiert")
        print("   ‚úÖ Code-Snippets mit Metadaten")
        print("   ‚úÖ Referenzen und Links erkannt")
        print("   ‚úÖ Metadaten vollst√§ndig extrahiert")
        print("   ‚úÖ Strukturierte Inhalte aufbereitet")
        print("\nüöÄ Bereit f√ºr Phase 2.3: Wissensbasis-Integration")
        
        return classification, result


if __name__ == "__main__":
    try:
        classification, result = demonstrate_phase2_workflow()
        
        # Optional: Save results for further processing
        print("\nüíæ Ergebnisse k√∂nnen nun in die Wissensbasis integriert werden")
        
    except Exception as e:
        print(f"\n‚ùå Fehler: {str(e)}")
        import traceback
        traceback.print_exc()